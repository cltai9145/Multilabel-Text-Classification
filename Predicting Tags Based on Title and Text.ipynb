{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Tags for Stack Overflow\n",
    "\n",
    "## Table of Contents\n",
    "* [Instructions](#Instructions)\n",
    "\n",
    "#### Part 1: Data Processing\n",
    "* [Import Modules](#Import-Modules)\n",
    "* [Import Data](#Import-Data)\n",
    "* [Data Cleaning](#Data-Cleaning)\n",
    "* [Analysis of Tags](#Analysis-of-Tags)\n",
    "\n",
    "#### Part 2: Machine Learning Models\n",
    "* [Bag of Words](#Bag-of-Words)\n",
    "* [OneVsRestClassifier with SGDClassifier](#OneVsRestClassifier-with-SGDClassifier)\n",
    "* [OneVsRestClassifier with DecisionTreeClassifier](#OneVsRestClassifier-with-DecisionTreeClassifier)\n",
    "* [OneVsRestClassifier with RidgeClassifier](#OneVsRestClassifier-with-RidgeClassifier)\n",
    "* [OneVsRestClassifier with KNeighborsClassifier](#OneVsRestClassifier-with-KNeighborsClassifier)\n",
    "* [OneVsRestClassifier with ExtraTreesClassifier](#OneVsRestClassifier-with-ExtraTreesClassifier)\n",
    "* [Adapted Algorithm: Multilabel k Nearest Neighbours](#Adapted-Algorithm:-Multilabel-k-Nearest-Neighbours)\n",
    "* [Evaluation Metrics for Different Models](#Evaluation-Metrics-for-Different-Models) \n",
    "* [Tuning CountVectorizer to Fit DecisionTreeClassifier](#Tuning-CountVectorizer-to-Fit-DecisionTreeClassifier)\n",
    "  * [Max_features: 50](#Max_features:-50)\n",
    "  * [Max_features: 100](#Max_features:-100)\n",
    "  * [Max_features: 200](#Max_features:-200)\n",
    "  * [Max_features: 300](#Max_features:-300)\n",
    "  * [Max_features: 400](#Max_features:-400)\n",
    "  * [Max_features: 500](#Max_features:-500)\n",
    "  * [Max_features: 1000](#Max_features:-1000)\n",
    "  * [Evaluation Metrics for DecisionTreeClassifier](#Evaluation-Metrics-for-DecisionTreeClassifier)\n",
    "  \n",
    "#### Part 3: Making Predictions\n",
    "* [Tags Prediction](#Tags-Prediction)\n",
    "\n",
    "## Instructions\n",
    "[Top](#Table-of-Contents)\n",
    "\n",
    "1. You will need to create Artificial Intelligence (AI) or Machine Learning (ML) models to predict tags or keywords based on the questions and titles.\n",
    "2. You will have 2 weeks to complete and send your code. \n",
    "3. You can use any programming language you like including R or Python. \n",
    "4. The accuracy of your model will be evaluated based on the F1 Score. The F1 Score, which is between 0% to 100%, provides a comprehensive measure of accuracy using both Precision and Recall.\n",
    "5. It's ok to just use the first or any random **5,000 rows** of the dataset since the size of the data is quite large.\n",
    "6. If you figure out how to manage the large dataset given your Memory or RAM limitation, that's even better.\n",
    "\n",
    "## Part 1: Data Processing\n",
    "### Import Modules\n",
    "[Top](#Part-1:-Data-Processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# data processing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# cleaning data\n",
    "import re\n",
    "import bs4\n",
    "import nltk\n",
    "import nltk.tokenize as tok\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# machine learning models\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.linear_model import SGDClassifier, RidgeClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from skmultilearn.adapt import MLkNN\n",
    "from sklearn.metrics import classification_report, f1_score, precision_score, recall_score, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\long\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\long\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data\n",
    "[Top](#Part-1:-Data-Processing)\n",
    "\n",
    "Selecting first 10,000 rows from the original dataset of 6,034,195 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>How to check if an uploaded file is an image w...</td>\n",
       "      <td>&lt;p&gt;I'd like to check if an uploaded file is an...</td>\n",
       "      <td>php image-processing file-upload upload mime-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>How can I prevent firefox from closing when I ...</td>\n",
       "      <td>&lt;p&gt;In my favorite editor (vim), I regularly us...</td>\n",
       "      <td>firefox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>R Error Invalid type (list) for variable</td>\n",
       "      <td>&lt;p&gt;I am import matlab file and construct a dat...</td>\n",
       "      <td>r matlab machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>How do I replace special characters in a URL?</td>\n",
       "      <td>&lt;p&gt;This is probably very simple, but I simply ...</td>\n",
       "      <td>c# url encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>How to modify whois contact details?</td>\n",
       "      <td>&lt;pre&gt;&lt;code&gt;function modify(.......)\\n{\\n  $mco...</td>\n",
       "      <td>php api file-get-contents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                              Title  \\\n",
       "0   1  How to check if an uploaded file is an image w...   \n",
       "1   2  How can I prevent firefox from closing when I ...   \n",
       "2   3           R Error Invalid type (list) for variable   \n",
       "3   4      How do I replace special characters in a URL?   \n",
       "4   5               How to modify whois contact details?   \n",
       "\n",
       "                                                Body  \\\n",
       "0  <p>I'd like to check if an uploaded file is an...   \n",
       "1  <p>In my favorite editor (vim), I regularly us...   \n",
       "2  <p>I am import matlab file and construct a dat...   \n",
       "3  <p>This is probably very simple, but I simply ...   \n",
       "4  <pre><code>function modify(.......)\\n{\\n  $mco...   \n",
       "\n",
       "                                                Tags  \n",
       "0  php image-processing file-upload upload mime-t...  \n",
       "1                                            firefox  \n",
       "2                          r matlab machine-learning  \n",
       "3                                    c# url encoding  \n",
       "4                          php api file-get-contents  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = 'Train.csv'\n",
    "no_of_rows = 10000\n",
    "df = pd.read_csv(filename, nrows = no_of_rows)\n",
    "print(df.shape)\n",
    "df.head()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "[Top](#Part-1:-Data-Processing)\n",
    "\n",
    "Remove unnecessary characters, html format and punctuation (but keeping words like c# since it's the most popular tag) as well as lowering text, transforming abbreviations, lemmatizing words and removing stop words from `Title` and `Body` column.\n",
    "\n",
    "Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meaning to one word.\n",
    "\n",
    "The process of converting data to something a computer can understand is referred to as pre-processing. One of the major forms of pre-processing is to filter out useless data. In natural language processing, useless words (data) are referred to as stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"can not \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\"\\'scuse\", \" excuse \", text)\n",
    "    text = re.sub(r\"\\'\\n\", \" \", text)\n",
    "    text = re.sub(r\"\\'\\xa0\", \" \", text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip(' ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_list_noempty(mylist):\n",
    "    newlist = (item.strip() if hasattr(item, 'strip') else item for item in mylist)\n",
    "    \n",
    "    return [item for item in newlist if item != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_punct(text): \n",
    "    words = token.tokenize(text)\n",
    "    punctuation_filtered = []\n",
    "    regex = re.compile('[%s]' % re.escape(punct))\n",
    "    remove_punctuation = str.maketrans(' ', ' ', punct)\n",
    "    \n",
    "    for w in words:\n",
    "        if w in tags_features:\n",
    "            punctuation_filtered.append(w)\n",
    "        else:\n",
    "            punctuation_filtered.append(regex.sub('', w))\n",
    "  \n",
    "    filtered_list = strip_list_noempty(punctuation_filtered)\n",
    "        \n",
    "    return ' '.join(map(str, filtered_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In grammar, inflection is the modification of a word to express different grammatical categories such as tense, case, voice, aspect, person, number, gender, and mood. An inflection expresses one or more grammatical categories with a prefix, suffix or infix, or another internal modification such as a vowel change.\n",
    "\n",
    "**Lemmatization** is the process of grouping together the different inflected forms of a word so they can be analysed as a single item. Lemmatization reduces the inflected words properly ensuring that the root word belongs to the language. In Lemmatization root word is called Lemma. A lemma (plural lemmas or lemmata) is the canonical form, dictionary form, or citation form of a set of words. Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meaning to one word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemitizeWords(text):\n",
    "    words = token.tokenize(text)\n",
    "    listLemma = []\n",
    "    \n",
    "    for w in words:\n",
    "        x = lemma.lemmatize(w, pos = \"v\")\n",
    "        listLemma.append(x)\n",
    "        \n",
    "    return ' '.join(map(str, listLemma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stop Words** are words which do not contain important significance to be used in Search Queries. Usually, these words are filtered out from search queries because they return a vast amount of unnecessary information. Each programming language will give its own list of stop words to use. Mostly they are words that are commonly used in the English language such as 'as, the, be, are' etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stopWordsRemove(text):\n",
    "    stop_words = set(stopwords.words(\"english\"))    \n",
    "    words = token.tokenize(text)\n",
    "    filtered = [w for w in words if not w in stop_words]\n",
    "    \n",
    "    return ' '.join(map(str, filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning data in the `Body` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 48.9 s\n",
    "\n",
    "flat_list = [item for sublist in df['Tags'].values for item in sublist]\n",
    "keywords = nltk.FreqDist(flat_list)\n",
    "keywords = nltk.FreqDist(keywords)\n",
    "frequencies_words = keywords.most_common(100)\n",
    "tags_features = [word[0] for word in frequencies_words]\n",
    "\n",
    "# ToktokTokenizer is a fast, simple, multilingual tokenizer. \n",
    "token = tok.ToktokTokenizer()\n",
    "lemma = WordNetLemmatizer()\n",
    "punct = '!\"$%&\\'()*,./:;<=>?@[\\\\]^_`{|}~'\n",
    "\n",
    "# Converting html to text in the body\n",
    "df['Body'] = df['Body'].apply(lambda x: bs4.BeautifulSoup(x, 'lxml').get_text()) \n",
    "df['Body'] = df['Body'].apply(lambda x: clean_text(x)) \n",
    "df['Body'] = df['Body'].apply(lambda x: clean_punct(x)) \n",
    "df['Body'] = df['Body'].apply(lambda x: lemitizeWords(x)) \n",
    "df['Body'] = df['Body'].apply(lambda x: stopWordsRemove(x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning data in the `Title` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.69 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 10.2 s\n",
    "\n",
    "df['Title'] = df['Title'].apply(lambda x: str(x))\n",
    "df['Title'] = df['Title'].apply(lambda x: clean_text(x)) \n",
    "df['Title'] = df['Title'].apply(lambda x: clean_punct(x)) \n",
    "df['Title'] = df['Title'].apply(lambda x: lemitizeWords(x)) \n",
    "df['Title'] = df['Title'].apply(lambda x: stopWordsRemove(x)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>check upload file image without mime type</td>\n",
       "      <td>would like check upload file image file eg png...</td>\n",
       "      <td>php image-processing file-upload upload mime-t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>prevent firefox close press ctrl-w</td>\n",
       "      <td>favorite editor vim regularly use ctrl-w execu...</td>\n",
       "      <td>firefox</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>r error invalid type list variable</td>\n",
       "      <td>import matlab file construct data frame matlab...</td>\n",
       "      <td>r matlab machine-learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>replace special character url</td>\n",
       "      <td>probably simple simply cannot find answer basi...</td>\n",
       "      <td>c# url encoding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>modify whois contact detail</td>\n",
       "      <td>function modify mcontact filegetcontents https...</td>\n",
       "      <td>php api file-get-contents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                      Title  \\\n",
       "0   1  check upload file image without mime type   \n",
       "1   2         prevent firefox close press ctrl-w   \n",
       "2   3         r error invalid type list variable   \n",
       "3   4              replace special character url   \n",
       "4   5                modify whois contact detail   \n",
       "\n",
       "                                                Body  \\\n",
       "0  would like check upload file image file eg png...   \n",
       "1  favorite editor vim regularly use ctrl-w execu...   \n",
       "2  import matlab file construct data frame matlab...   \n",
       "3  probably simple simply cannot find answer basi...   \n",
       "4  function modify mcontact filegetcontents https...   \n",
       "\n",
       "                                                Tags  \n",
       "0  php image-processing file-upload upload mime-t...  \n",
       "1                                            firefox  \n",
       "2                          r matlab machine-learning  \n",
       "3                                    c# url encoding  \n",
       "4                          php api file-get-contents  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of Tags\n",
    "[Top](#Part-1:-Data-Processing)\n",
    "\n",
    "Text preprocessing, tokenizing and filtering of stopwords are all included in `CountVectorizer` which builds a dictionary of features and transforms documents to feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of data points : 10000\n",
      "Number of unique tags : 6124\n"
     ]
    }
   ],
   "source": [
    "# using split() to tokenize each tag using space.\n",
    "vectorizer = CountVectorizer(tokenizer = lambda x: x.split())\n",
    "\n",
    "# fit_transform() does two functions: \n",
    "# 1. it fits the model and learns the vocabulary; \n",
    "# 2. it transforms training data into feature vectors. The input to fit_transform should be a list of strings.\n",
    "tags = vectorizer.fit_transform(df['Tags'])\n",
    "\n",
    "print(\"Number of data points :\", tags.shape[0])\n",
    "print(\"Number of unique tags :\", tags.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of the tags found in the dataset:\n",
      "['.htaccess', '.net', '.net-2.0', '.net-3.5', '.net-4.0', '.net-4.5', '.net-assembly', '.net-framework', '.net4.0', '.refresh']\n"
     ]
    }
   ],
   "source": [
    "# get_feature_name() gives the vocabulary.\n",
    "tags_feat = vectorizer.get_feature_names()\n",
    "\n",
    "print(\"Some of the tags found in the dataset:\")\n",
    "print(tags_feat[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total datapoints: 10000\n",
      "Number of tags for the first 10 questions: [5, 1, 3, 3, 3, 3, 1, 3, 3, 5]\n"
     ]
    }
   ],
   "source": [
    "# Storing the count of tag in each question to list 'tag_count'\n",
    "tag_count = tags.sum(axis = 1).tolist()\n",
    "\n",
    "# Converting each value in the 'tag_count' to integer.\n",
    "tag_count = [int(j) for i in tag_count for j in i]\n",
    "\n",
    "print('Total datapoints:', len(tag_count))\n",
    "print('Number of tags for the first 10 questions:', tag_count[:10]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(tag_count, palette = 'gist_rainbow')\n",
    "plt.title(\"Number of Tags in The Questions \")\n",
    "plt.xlabel(\"Number of Tags\")\n",
    "plt.ylabel(\"Number of questions\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>.htaccess</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>.net</td>\n",
       "      <td>302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.net-2.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>.net-3.5</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.net-4.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Tags  Frequency\n",
       "0  .htaccess         40\n",
       "1       .net        302\n",
       "2   .net-2.0          6\n",
       "3   .net-3.5          7\n",
       "4   .net-4.0         10"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count frequency of each tag\n",
    "freqs = tags.sum(axis = 0).A1 \n",
    "tags_freq = pd.DataFrame(tags_feat, columns = ['Tags'])\n",
    "tags_freq['Frequency'] = freqs\n",
    "tags_freq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tags</th>\n",
       "      <th>Frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>c#</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2666</th>\n",
       "      <td>java</td>\n",
       "      <td>703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3937</th>\n",
       "      <td>php</td>\n",
       "      <td>701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>javascript</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>android</td>\n",
       "      <td>518</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Tags  Frequency\n",
       "674           c#        778\n",
       "2666        java        703\n",
       "3937         php        701\n",
       "2685  javascript        624\n",
       "179      android        518"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort each tag in descending order according ot the number of occurence\n",
    "sorted_tags = tags_freq.sort_values(['Frequency'], ascending = False) \n",
    "sorted_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = np.arange(30)\n",
    "sorted_tags.head(30).plot(figsize = (18, 6), kind = 'bar')\n",
    "plt.title('Frequency of Top 30 Tags')\n",
    "plt.xticks(i, sorted_tags['Tags'])\n",
    "plt.xlabel('Tags')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Machine Learning Models\n",
    "### Bag of Words\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "**Bag of Words** is a simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity. \n",
    "\n",
    "The input data is in the form of words and characters. So it needs to be converted into numeric format that the model can understand. An array of the top words will be created and a comment will be represented by a dense vector with 0 or 1 indicating the absence or presence of a given keyword or tag from the vocabulary in a comment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>check upload file image without mime type</td>\n",
       "      <td>would like check upload file image file eg png...</td>\n",
       "      <td>php image-processing file-upload upload mime-t...</td>\n",
       "      <td>check upload file image without mime type woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>prevent firefox close press ctrl-w</td>\n",
       "      <td>favorite editor vim regularly use ctrl-w execu...</td>\n",
       "      <td>firefox</td>\n",
       "      <td>prevent firefox close press ctrl-w favorite ed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>r error invalid type list variable</td>\n",
       "      <td>import matlab file construct data frame matlab...</td>\n",
       "      <td>r matlab machine-learning</td>\n",
       "      <td>r error invalid type list variable import matl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>replace special character url</td>\n",
       "      <td>probably simple simply cannot find answer basi...</td>\n",
       "      <td>c# url encoding</td>\n",
       "      <td>replace special character url probably simple ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>modify whois contact detail</td>\n",
       "      <td>function modify mcontact filegetcontents https...</td>\n",
       "      <td>php api file-get-contents</td>\n",
       "      <td>modify whois contact detail function modify mc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id                                      Title  \\\n",
       "0   1  check upload file image without mime type   \n",
       "1   2         prevent firefox close press ctrl-w   \n",
       "2   3         r error invalid type list variable   \n",
       "3   4              replace special character url   \n",
       "4   5                modify whois contact detail   \n",
       "\n",
       "                                                Body  \\\n",
       "0  would like check upload file image file eg png...   \n",
       "1  favorite editor vim regularly use ctrl-w execu...   \n",
       "2  import matlab file construct data frame matlab...   \n",
       "3  probably simple simply cannot find answer basi...   \n",
       "4  function modify mcontact filegetcontents https...   \n",
       "\n",
       "                                                Tags  \\\n",
       "0  php image-processing file-upload upload mime-t...   \n",
       "1                                            firefox   \n",
       "2                          r matlab machine-learning   \n",
       "3                                    c# url encoding   \n",
       "4                          php api file-get-contents   \n",
       "\n",
       "                                                Post  \n",
       "0  check upload file image without mime type woul...  \n",
       "1  prevent firefox close press ctrl-w favorite ed...  \n",
       "2  r error invalid type list variable import matl...  \n",
       "3  replace special character url probably simple ...  \n",
       "4  modify whois contact detail function modify mc...  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Post'] = df['Title'].map(str) + \" \" + df['Body']\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TF-IDF** is an acronym than stands for 'Term Frequency – Inverse Document Frequency' which are the components of the resulting scores assigned to each word.\n",
    "\n",
    "* Term Frequency summarizes how often a given word appears within a document.\n",
    "* Inverse Document Frequency downscales words that appear a lot across documents.\n",
    "\n",
    "TF-IDF are word frequency scores that try to highlight words that are more interesting or frequent found in document but not across documents. `TfidfVectorizer` tokenizes documents, learns the vocabulary and inverses document frequency weightings and to encode new documents. It convert texts to a matrix of TF-IDF features.\n",
    "\n",
    "`CountVectorizer` on the other hand converts a collection of text documents to a matrix of token counts.\n",
    "\n",
    "Setting train and test split ratio to 80/20 for train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200000) (2000, 200000) (8000, 500) (2000, 500)\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(min_df = 0.00009, max_features = 200000, smooth_idf = True, norm = \"l2\", \n",
    "                                   tokenizer = lambda x: x.split(), sublinear_tf = False, ngram_range = (1, 2))\n",
    "count_vectorizer = CountVectorizer(tokenizer = lambda x: x.split(), binary = 'true', max_features = 500)\n",
    "\n",
    "vectorize_post = tfidf_vectorizer.fit_transform(df['Post'])\n",
    "vectorize_tags = count_vectorizer.fit_transform(df['Tags'])\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(vectorize_post, vectorize_tags, random_state = 42, test_size = 0.2, \n",
    "                                                    shuffle = False)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the keywords found in vectorized `Post` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['apply two', 'apply update', 'apply value', 'apply would', 'apply-templates', 'apply-templates select', 'apply-templates table', 'apply-templates xsl', 'applycommand', 'applycommand get', 'applycommand new', 'applycommand null', 'applycommand public', 'applyconfiguration', 'applyfilters', 'applyrelops', 'applyrelops df', 'applyrequestvalues', 'applyrequestvalues 2', 'appmainloop', 'appmanager-findbyappleid', 'appmanager-findbyappleid 547409501', 'appmobi', 'appmodel', 'appmonster', 'appname', 'appointment', 'appointmentid', 'appointments', 'appointmentstatusid', 'appostrophes', 'apppath', 'appphp', 'apprakefile', 'apprakefile 7', 'appreaciated', 'appreciate', 'appreciate -', 'appreciate --', 'appreciate .', 'appreciate answer', 'appreciate anyone', 'appreciate assistance', 'appreciate cheer', 'appreciate code', 'appreciate could', 'appreciate define', 'appreciate edit', 'appreciate feedback', 'appreciate follow']\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectorizer.get_feature_names()[20000:20050])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the tags found in vectorized `Tags` column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http', 'https', 'ide', 'if-statement', 'iis', 'iis7', 'image', 'image-processing', 'import', 'index', 'inheritance', 'input', 'insert', 'installation', 'interface', 'interface-builder', 'internet-explorer', 'ios', 'ios4', 'ios5', 'ios6', 'ipad', 'iphone', 'iphone-sdk-4.0', 'iptables', 'jar', 'java', 'java-ee', 'javascript', 'javascript-events', 'join', 'joomla', 'jpa', 'jqgrid', 'jquery', 'jquery-ajax', 'jquery-mobile', 'jquery-plugins', 'jquery-selectors', 'jquery-ui', 'jsf', 'jsf-2', 'json', 'jsp', 'jvm', 'keyboard', 'lambda', 'layout', 'licensing', 'limit']\n"
     ]
    }
   ],
   "source": [
    "print(count_vectorizer.get_feature_names()[200:250])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneVsRestClassifier with SGDClassifier\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "`One-vs-the-rest` strategy consists in fitting one classifier per class. For each classifier, the class is fitted against all the other classes.  In addition to its computational efficiency (only n_classes classifiers are needed), one advantage of this approach is its interpretability. Since each class is represented by one and one classifier only, it is possible to gain knowledge about the class by inspecting its corresponding classifier. This is the most commonly used strategy for multiclass classification and is a fair default choice.\n",
    "\n",
    "`SGDClassifier` is a Linear classifiers (SVM, logistic regression) with SGD training. This estimator implements regularized linear models with stochastic gradient descent (SGD) learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule (aka learning rate). The model it fits can be controlled with the loss parameter. By default, it fits a linear support vector machine (SVM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, x_train, x_test, y_train, y_test):\n",
    "    model_name = model\n",
    "    model_name.fit(x_train, y_train)\n",
    "    y_pred = model_name.predict(x_test)\n",
    "\n",
    "    f1 = f1_score(y_test, y_pred, average = 'micro')\n",
    "    precision = precision_score(y_test, y_pred, average = 'micro')\n",
    "    recall = recall_score(y_test, y_pred, average = 'micro')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Evaluation Metrics \n",
    "    print(\"Micro F1 Score: %.3f\" % (f1))\n",
    "    print(\"Micro Precision: %.3f\" % (precision))\n",
    "    print(\"Micro Recall: %.3f\" % (recall))\n",
    "    print(\"Accuracy: %.3f\" % (accuracy))\n",
    "    \n",
    "    return f1, precision, recall, accuracy, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.345\n",
      "Micro Precision: 0.745\n",
      "Micro Recall: 0.225\n",
      "Accuracy: 0.187\n",
      "Wall time: 46 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 1min 2s\n",
    "\n",
    "sgd = SGDClassifier(loss = 'log', alpha = 0.00001, penalty = 'l1') \n",
    "sgd_f1, sgd_precision, sgd_recall, sgd_accuracy, y_pred_sgd = train_model(OneVsRestClassifier(sgd, n_jobs = -1), \n",
    "                                                                          x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneVsRestClassifier with DecisionTreeClassifier\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "`DecisionTreeClassifier` is a class capable of performing multi-class classification on a dataset. As with other classifiers, it takes inputs as two arrays: an array X holding the training samples and an array Y of integer values holding the class labels for the training samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.408\n",
      "Micro Precision: 0.441\n",
      "Micro Recall: 0.379\n",
      "Accuracy: 0.139\n",
      "Wall time: 17min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 17min 22s\n",
    "\n",
    "dtc = DecisionTreeClassifier() \n",
    "dt_f1, dt_precision, dt_recall, dt_accuracy, y_pred_dt = train_model(OneVsRestClassifier(dtc, n_jobs = -1), \n",
    "                                                                     x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneVsRestClassifier with RidgeClassifier\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "It is a classifier using Ridge regression. Ridge regression avoids over-fitting by regularising the weights to keep them small and model selection is straight forward because only have to choose the value of a single regression parameter. Sometimes model selection becomes difficult as there is a degree of freedom for each feature which makes it possible to over-fit the feature selection criterion and might end up with a set of features that is optimal for this particular sample of data but gives poor generalisation performance. So not performing feature selection and using regularisation can often give better predictive performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.186\n",
      "Micro Precision: 0.868\n",
      "Micro Recall: 0.104\n",
      "Accuracy: 0.144\n",
      "Wall time: 5min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 5min 3s\n",
    "\n",
    "rc = RidgeClassifier() \n",
    "rc_f1, rc_precision, rc_recall, rc_accuracy, y_pred_rc = train_model(OneVsRestClassifier(rc, n_jobs = -1), \n",
    "                                                                     x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneVsRestClassifier with KNeighborsClassifier\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "`KNeighborsClassifier` is a classifier implementing the $k$-nearest neighbors vote. It implements learning based on the $k$ nearest neighbors of each query point where $k$ is an integer value specified by the user. The $k$-neighbors classification in `KNeighborsClassifier` is the most commonly used technique. The optimal choice of the value $k$ is highly data-dependent: in general a larger $k$ suppresses the effects of noise but makes the classification boundaries less distinct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.226\n",
      "Micro Precision: 0.598\n",
      "Micro Recall: 0.140\n",
      "Accuracy: 0.143\n",
      "Wall time: 15min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 15min 7s\n",
    "\n",
    "knc = KNeighborsClassifier()\n",
    "knn_f1, knn_precision, knn_recall, knn_accuracy, y_pred_knn = train_model(OneVsRestClassifier(knc, n_jobs = -1), \n",
    "                                                                          x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneVsRestClassifier with ExtraTreesClassifier\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "`ExtraTreesClassifier` is an ensemble learning method fundamentally based on decision trees. `ExtraTreesClassifier` like RandomForest, randomizes certain decisions and subsets of data to minimize over-learning from the data and overfitting. Like Random Forest, it builds multiple trees and splits nodes using random subsets of features but with two key differences: \n",
    "1. It does not bootstrap observations (meaning it samples without replacement)\n",
    "2. Nodes are split on random splits but not best splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.075\n",
      "Micro Precision: 0.832\n",
      "Micro Recall: 0.039\n",
      "Accuracy: 0.115\n",
      "Wall time: 11min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 14min 28s\n",
    "\n",
    "etc = ExtraTreesClassifier() \n",
    "et_f1, et_precision, et_recall, et_accuracy, y_pred_et = train_model(OneVsRestClassifier(etc, n_jobs = -1), \n",
    "                                                                     x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adapted Algorithm: Multilabel k Nearest Neighbours\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "`MLkNN` uses k-NearestNeighbors to find nearest examples to a test class and uses Bayesian inference to select assigned labels. It is an adaptation of kNN for multi-label classification. In essence, `ML-kNN` uses the `kNN` algorithm independently for each label. It finds the k nearest examples to the test instance and considers those that are labeled at least with l as positive and the rest as negative. What mainly differentiates this method from other binary relevance (BR) methods is the use of prior probabilities. It can also rank labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro F1 Score: 0.254\n",
      "Micro Precision: 0.574\n",
      "Micro Recall: 0.163\n",
      "Accuracy: 0.149\n",
      "Wall time: 3min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 4min 36s\n",
    "\n",
    "MLkNN_f1, MLkNN_precision, MLkNN_recall, MLkNN_accuracy, y_predMLkNN = train_model(MLkNN(k = 10), \n",
    "                                                                                   x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics for Different Models\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "The table below shows that `DecisionTreeClassifier` gives the highest Micro F1 Score. This classifier will be fine-tuned before making predictions. Micro F1-Score is used here because more weightages are given on how frequently the tags occur. Micro F1-Score is taking the tag frequency of occurrence into consideration when it is computing the micro precision and recall. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Micro F1 Score</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SGDClassifier</th>\n",
       "      <td>0.345477</td>\n",
       "      <td>0.745257</td>\n",
       "      <td>0.224857</td>\n",
       "      <td>0.1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.407625</td>\n",
       "      <td>0.441130</td>\n",
       "      <td>0.378850</td>\n",
       "      <td>0.1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RidgeClassifier</th>\n",
       "      <td>0.186375</td>\n",
       "      <td>0.868481</td>\n",
       "      <td>0.104388</td>\n",
       "      <td>0.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNeighborsClassifier</th>\n",
       "      <td>0.226298</td>\n",
       "      <td>0.598131</td>\n",
       "      <td>0.139548</td>\n",
       "      <td>0.1435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ExtraTreesClassifier</th>\n",
       "      <td>0.074961</td>\n",
       "      <td>0.832370</td>\n",
       "      <td>0.039248</td>\n",
       "      <td>0.1145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multilabel k Nearest Neighbours</th>\n",
       "      <td>0.254191</td>\n",
       "      <td>0.573755</td>\n",
       "      <td>0.163260</td>\n",
       "      <td>0.1490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Micro F1 Score  Micro Precision  \\\n",
       "SGDClassifier                          0.345477         0.745257   \n",
       "DecisionTreeClassifier                 0.407625         0.441130   \n",
       "RidgeClassifier                        0.186375         0.868481   \n",
       "KNeighborsClassifier                   0.226298         0.598131   \n",
       "ExtraTreesClassifier                   0.074961         0.832370   \n",
       "Multilabel k Nearest Neighbours        0.254191         0.573755   \n",
       "\n",
       "                                 Micro Recall  Accuracy  \n",
       "SGDClassifier                        0.224857    0.1870  \n",
       "DecisionTreeClassifier               0.378850    0.1385  \n",
       "RidgeClassifier                      0.104388    0.1445  \n",
       "KNeighborsClassifier                 0.139548    0.1435  \n",
       "ExtraTreesClassifier                 0.039248    0.1145  \n",
       "Multilabel k Nearest Neighbours      0.163260    0.1490  "
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.DataFrame({'Micro F1 Score': sgd_f1, 'Micro Precision': sgd_precision, 'Micro Recall': sgd_recall, \n",
    "                        'Accuracy': sgd_accuracy}, index = ['SGDClassifier'])\n",
    "results.loc['DecisionTreeClassifier'] = dt_f1, dt_precision, dt_recall, dt_accuracy\n",
    "results.loc['RidgeClassifier'] = rc_f1, rc_precision, rc_recall, rc_accuracy\n",
    "results.loc['KNeighborsClassifier'] = knn_f1, knn_precision, knn_recall, knn_accuracy\n",
    "results.loc['ExtraTreesClassifier'] = et_f1, et_precision, et_recall, et_accuracy\n",
    "results.loc['Multilabel k Nearest Neighbours'] = MLkNN_f1, MLkNN_precision, MLkNN_recall, MLkNN_accuracy\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The table below shows the classification report for `DecisionTreeClassifier`. <br>\n",
    "[Skip report](#Tuning-CountVectorizer-to-Fit-DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.83      0.67         6\n",
      "          1       0.19      0.09      0.12        65\n",
      "          2       0.00      0.00      0.00         2\n",
      "          3       0.00      0.00      0.00         1\n",
      "          4       0.00      0.00      0.00         3\n",
      "          5       0.00      0.00      0.00         3\n",
      "          6       0.50      0.33      0.40         3\n",
      "          7       1.00      0.38      0.56        13\n",
      "          8       0.25      0.25      0.25         4\n",
      "          9       0.00      0.00      0.00         2\n",
      "         10       0.00      0.00      0.00         4\n",
      "         11       0.00      0.00      0.00         5\n",
      "         12       0.36      0.33      0.34        15\n",
      "         13       0.00      0.00      0.00         3\n",
      "         14       0.22      0.18      0.20        11\n",
      "         15       0.00      0.00      0.00         0\n",
      "         16       1.00      1.00      1.00         1\n",
      "         17       0.00      0.00      0.00         0\n",
      "         18       0.79      0.67      0.73        91\n",
      "         19       0.00      0.00      0.00         4\n",
      "         20       0.00      0.00      0.00         6\n",
      "         21       0.80      0.80      0.80         5\n",
      "         22       0.00      0.00      0.00         1\n",
      "         23       0.25      0.20      0.22         5\n",
      "         24       0.50      0.33      0.40         3\n",
      "         25       0.00      0.00      0.00        10\n",
      "         26       0.14      0.25      0.18         4\n",
      "         27       0.20      0.20      0.20         5\n",
      "         28       0.00      0.00      0.00         2\n",
      "         29       0.00      0.00      0.00         4\n",
      "         30       0.00      0.00      0.00         4\n",
      "         31       0.09      0.05      0.06        21\n",
      "         32       0.80      0.80      0.80         5\n",
      "         33       0.52      0.43      0.47        75\n",
      "         34       0.50      0.43      0.46        21\n",
      "         35       0.00      0.00      0.00         2\n",
      "         36       0.45      0.33      0.38        15\n",
      "         37       0.00      0.00      0.00         2\n",
      "         38       0.33      0.25      0.29         4\n",
      "         39       0.00      0.00      0.00         1\n",
      "         40       0.00      0.00      0.00         0\n",
      "         41       0.57      0.57      0.57         7\n",
      "         42       0.17      0.14      0.15         7\n",
      "         43       0.00      0.00      0.00         2\n",
      "         44       0.00      0.00      0.00         3\n",
      "         45       0.67      1.00      0.80         2\n",
      "         46       0.00      0.00      0.00         1\n",
      "         47       0.40      0.40      0.40         5\n",
      "         48       0.60      0.25      0.35        12\n",
      "         49       0.25      0.50      0.33         2\n",
      "         50       0.00      0.00      0.00         3\n",
      "         51       0.33      0.33      0.33         3\n",
      "         52       0.86      1.00      0.92         6\n",
      "         53       0.00      0.00      0.00         0\n",
      "         54       0.00      0.00      0.00         2\n",
      "         55       0.50      0.50      0.50         2\n",
      "         56       0.00      0.00      0.00         1\n",
      "         57       0.20      0.20      0.20         5\n",
      "         58       0.00      0.00      0.00         3\n",
      "         59       0.38      0.36      0.37        44\n",
      "         60       0.46      0.42      0.44       158\n",
      "         61       0.00      0.00      0.00         4\n",
      "         62       0.59      0.48      0.53        71\n",
      "         63       0.00      0.00      0.00         2\n",
      "         64       0.00      0.00      0.00         4\n",
      "         65       1.00      0.71      0.83         7\n",
      "         66       0.80      0.57      0.67         7\n",
      "         67       0.45      0.50      0.48        10\n",
      "         68       0.00      0.00      0.00         3\n",
      "         69       1.00      0.40      0.57         5\n",
      "         70       0.00      0.00      0.00         1\n",
      "         71       0.00      0.00      0.00         7\n",
      "         72       0.17      1.00      0.29         1\n",
      "         73       0.57      0.36      0.44        11\n",
      "         74       0.08      0.10      0.09        10\n",
      "         75       0.33      1.00      0.50         1\n",
      "         76       0.88      0.50      0.64        14\n",
      "         77       0.00      0.00      0.00         1\n",
      "         78       0.50      0.25      0.33         4\n",
      "         79       0.00      0.00      0.00         0\n",
      "         80       0.00      0.00      0.00         3\n",
      "         81       0.00      0.00      0.00         3\n",
      "         82       0.00      0.00      0.00         2\n",
      "         83       0.00      0.00      0.00         1\n",
      "         84       0.14      0.25      0.18         4\n",
      "         85       1.00      0.33      0.50         3\n",
      "         86       0.00      0.00      0.00         3\n",
      "         87       1.00      0.75      0.86         4\n",
      "         88       0.00      0.00      0.00         3\n",
      "         89       0.00      0.00      0.00         4\n",
      "         90       0.00      0.00      0.00         2\n",
      "         91       1.00      0.33      0.50         3\n",
      "         92       0.40      0.50      0.44         4\n",
      "         93       0.00      0.00      0.00         0\n",
      "         94       0.00      0.00      0.00         1\n",
      "         95       1.00      1.00      1.00         2\n",
      "         96       0.46      0.43      0.45        44\n",
      "         97       0.33      0.33      0.33         3\n",
      "         98       0.33      0.50      0.40         2\n",
      "         99       1.00      0.67      0.80         3\n",
      "        100       0.00      0.00      0.00         3\n",
      "        101       0.00      0.00      0.00         2\n",
      "        102       0.75      0.75      0.75         4\n",
      "        103       0.00      0.00      0.00         3\n",
      "        104       0.00      0.00      0.00         6\n",
      "        105       0.14      0.14      0.14        21\n",
      "        106       0.67      0.40      0.50         5\n",
      "        107       0.00      0.00      0.00         2\n",
      "        108       0.00      0.00      0.00         1\n",
      "        109       0.33      0.17      0.22         6\n",
      "        110       0.75      0.50      0.60         6\n",
      "        111       0.00      0.00      0.00         7\n",
      "        112       0.00      0.00      0.00         0\n",
      "        113       0.00      0.00      0.00         3\n",
      "        114       1.00      0.80      0.89         5\n",
      "        115       0.50      0.50      0.50         2\n",
      "        116       0.00      0.00      0.00         6\n",
      "        117       0.00      0.00      0.00         8\n",
      "        118       0.40      0.33      0.36         6\n",
      "        119       0.00      0.00      0.00         3\n",
      "        120       0.00      0.00      0.00         1\n",
      "        121       0.00      0.00      0.00         1\n",
      "        122       0.00      0.00      0.00         2\n",
      "        123       0.73      0.80      0.76        10\n",
      "        124       0.00      0.00      0.00         2\n",
      "        125       0.00      0.00      0.00         1\n",
      "        126       1.00      0.33      0.50         3\n",
      "        127       0.33      1.00      0.50         1\n",
      "        128       0.00      0.00      0.00         1\n",
      "        129       0.00      0.00      0.00         3\n",
      "        130       0.00      0.00      0.00         1\n",
      "        131       0.75      0.86      0.80         7\n",
      "        132       0.33      0.25      0.29         4\n",
      "        133       0.60      0.56      0.58        16\n",
      "        134       1.00      0.75      0.86         4\n",
      "        135       0.33      0.22      0.27         9\n",
      "        136       0.25      0.25      0.25         4\n",
      "        137       0.40      0.50      0.44         4\n",
      "        138       0.43      0.30      0.35        10\n",
      "        139       1.00      0.25      0.40         4\n",
      "        140       0.00      0.00      0.00         0\n",
      "        141       0.00      0.00      0.00         2\n",
      "        142       0.33      0.40      0.36         5\n",
      "        143       0.36      0.56      0.43         9\n",
      "        144       0.00      0.00      0.00         3\n",
      "        145       0.00      0.00      0.00         2\n",
      "        146       0.00      0.00      0.00         1\n",
      "        147       0.67      1.00      0.80         2\n",
      "        148       0.73      0.50      0.59        16\n",
      "        149       0.50      0.25      0.33         4\n",
      "        150       0.00      0.00      0.00        11\n",
      "        151       0.00      0.00      0.00         1\n",
      "        152       0.00      0.00      0.00         1\n",
      "        153       0.00      0.00      0.00         2\n",
      "        154       0.00      0.00      0.00         3\n",
      "        155       0.40      0.40      0.40         5\n",
      "        156       0.69      0.64      0.67        14\n",
      "        157       0.43      0.43      0.43         7\n",
      "        158       0.00      0.00      0.00         0\n",
      "        159       0.00      0.00      0.00         3\n",
      "        160       0.50      0.17      0.25         6\n",
      "        161       0.00      0.00      0.00         2\n",
      "        162       0.00      0.00      0.00         6\n",
      "        163       0.00      0.00      0.00         4\n",
      "        164       0.00      0.00      0.00         0\n",
      "        165       0.00      0.00      0.00         5\n",
      "        166       0.25      1.00      0.40         1\n",
      "        167       0.00      0.00      0.00         0\n",
      "        168       0.50      1.00      0.67         1\n",
      "        169       0.67      0.50      0.57         4\n",
      "        170       0.50      0.50      0.50         2\n",
      "        171       0.17      1.00      0.29         1\n",
      "        172       0.00      0.00      0.00         4\n",
      "        173       0.60      0.55      0.57        11\n",
      "        174       0.33      0.33      0.33         3\n",
      "        175       0.00      0.00      0.00         4\n",
      "        176       1.00      0.50      0.67         8\n",
      "        177       0.20      0.17      0.18         6\n",
      "        178       0.33      0.50      0.40         4\n",
      "        179       0.20      0.33      0.25         3\n",
      "        180       0.00      0.00      0.00         2\n",
      "        181       1.00      1.00      1.00         3\n",
      "        182       0.00      0.00      0.00         2\n",
      "        183       0.00      0.00      0.00         6\n",
      "        184       0.33      1.00      0.50         1\n",
      "        185       0.00      0.00      0.00         3\n",
      "        186       0.67      1.00      0.80         2\n",
      "        187       0.00      0.00      0.00         3\n",
      "        188       0.00      0.00      0.00         4\n",
      "        189       0.67      1.00      0.80         2\n",
      "        190       0.25      0.50      0.33         2\n",
      "        191       1.00      0.33      0.50         3\n",
      "        192       0.50      0.80      0.62         5\n",
      "        193       0.00      0.00      0.00         3\n",
      "        194       1.00      0.50      0.67         4\n",
      "        195       0.50      1.00      0.67         4\n",
      "        196       0.00      0.00      0.00         7\n",
      "        197       0.20      0.11      0.14        64\n",
      "        198       0.57      0.57      0.57        14\n",
      "        199       0.33      0.67      0.44         3\n",
      "        200       0.00      0.00      0.00         4\n",
      "        201       1.00      1.00      1.00         2\n",
      "        202       0.00      0.00      0.00         1\n",
      "        203       0.00      0.00      0.00         6\n",
      "        204       0.43      0.30      0.35        10\n",
      "        205       0.67      0.89      0.76         9\n",
      "        206       0.33      0.17      0.22        12\n",
      "        207       0.00      0.00      0.00         3\n",
      "        208       0.00      0.00      0.00         3\n",
      "        209       0.00      0.00      0.00         2\n",
      "        210       1.00      0.12      0.22         8\n",
      "        211       0.00      0.00      0.00         3\n",
      "        212       0.00      0.00      0.00         1\n",
      "        213       0.00      0.00      0.00         5\n",
      "        214       0.00      0.00      0.00         0\n",
      "        215       0.33      1.00      0.50         1\n",
      "        216       0.00      0.00      0.00         4\n",
      "        217       0.44      0.40      0.42        40\n",
      "        218       0.00      0.00      0.00         0\n",
      "        219       0.00      0.00      0.00         6\n",
      "        220       0.00      0.00      0.00         2\n",
      "        221       0.38      0.43      0.40         7\n",
      "        222       0.42      0.41      0.42        54\n",
      "        223       0.00      0.00      0.00         5\n",
      "        224       1.00      1.00      1.00         2\n",
      "        225       0.00      0.00      0.00         1\n",
      "        226       0.56      0.51      0.53       138\n",
      "        227       0.00      0.00      0.00         4\n",
      "        228       0.55      0.43      0.49       122\n",
      "        229       0.00      0.00      0.00         4\n",
      "        230       0.33      0.25      0.29         4\n",
      "        231       0.33      0.50      0.40         2\n",
      "        232       1.00      0.33      0.50         3\n",
      "        233       1.00      1.00      1.00         2\n",
      "        234       0.69      0.71      0.70        95\n",
      "        235       0.00      0.00      0.00         8\n",
      "        236       1.00      1.00      1.00         2\n",
      "        237       0.00      0.00      0.00         4\n",
      "        238       0.00      0.00      0.00         1\n",
      "        239       0.40      0.50      0.44         4\n",
      "        240       1.00      0.36      0.53        14\n",
      "        241       0.00      0.00      0.00         2\n",
      "        242       0.20      0.30      0.24        10\n",
      "        243       0.38      0.56      0.45         9\n",
      "        244       0.00      0.00      0.00         1\n",
      "        245       0.00      0.00      0.00         4\n",
      "        246       0.50      0.25      0.33         4\n",
      "        247       0.00      0.00      0.00         2\n",
      "        248       0.00      0.00      0.00         1\n",
      "        249       0.50      0.33      0.40         3\n",
      "        250       0.00      0.00      0.00         3\n",
      "        251       0.56      0.53      0.55        17\n",
      "        252       0.00      0.00      0.00         2\n",
      "        253       0.50      0.67      0.57         3\n",
      "        254       0.44      0.30      0.35        47\n",
      "        255       0.00      0.00      0.00         3\n",
      "        256       0.00      0.00      0.00         5\n",
      "        257       0.00      0.00      0.00         6\n",
      "        258       0.00      0.00      0.00         1\n",
      "        259       0.00      0.00      0.00         2\n",
      "        260       0.25      0.25      0.25         4\n",
      "        261       1.00      0.25      0.40         4\n",
      "        262       0.50      0.20      0.29         5\n",
      "        263       0.00      0.00      0.00         1\n",
      "        264       1.00      1.00      1.00         1\n",
      "        265       0.00      0.00      0.00         1\n",
      "        266       0.00      0.00      0.00         1\n",
      "        267       0.00      0.00      0.00         2\n",
      "        268       0.33      0.20      0.25         5\n",
      "        269       0.88      0.88      0.88         8\n",
      "        270       0.00      0.00      0.00         2\n",
      "        271       0.00      0.00      0.00         2\n",
      "        272       0.00      0.00      0.00         3\n",
      "        273       0.62      0.83      0.71         6\n",
      "        274       0.00      0.00      0.00         0\n",
      "        275       0.50      1.00      0.67         2\n",
      "        276       1.00      1.00      1.00         1\n",
      "        277       0.50      0.25      0.33         8\n",
      "        278       0.00      0.00      0.00         3\n",
      "        279       0.00      0.00      0.00         7\n",
      "        280       0.00      0.00      0.00         1\n",
      "        281       0.00      0.00      0.00         0\n",
      "        282       0.00      0.00      0.00         5\n",
      "        283       0.00      0.00      0.00         2\n",
      "        284       0.00      0.00      0.00         0\n",
      "        285       0.00      0.00      0.00         3\n",
      "        286       0.00      0.00      0.00         3\n",
      "        287       0.80      0.80      0.80         5\n",
      "        288       0.67      0.50      0.57         4\n",
      "        289       0.50      0.50      0.50         2\n",
      "        290       0.50      1.00      0.67         1\n",
      "        291       1.00      0.50      0.67         4\n",
      "        292       0.00      0.00      0.00         3\n",
      "        293       0.33      0.33      0.33        15\n",
      "        294       0.25      0.33      0.29         3\n",
      "        295       1.00      1.00      1.00         1\n",
      "        296       0.61      0.68      0.64        53\n",
      "        297       0.00      0.00      0.00         1\n",
      "        298       0.00      0.00      0.00         1\n",
      "        299       0.00      0.00      0.00        11\n",
      "        300       1.00      1.00      1.00         7\n",
      "        301       0.83      0.83      0.83         6\n",
      "        302       1.00      0.17      0.29         6\n",
      "        303       0.00      0.00      0.00         1\n",
      "        304       0.50      0.33      0.40         3\n",
      "        305       0.50      0.20      0.29         5\n",
      "        306       0.00      0.00      0.00         3\n",
      "        307       0.13      0.11      0.12        37\n",
      "        308       0.00      0.00      0.00         8\n",
      "        309       1.00      1.00      1.00         3\n",
      "        310       0.50      0.67      0.57         3\n",
      "        311       0.00      0.00      0.00         2\n",
      "        312       0.00      0.00      0.00         1\n",
      "        313       0.14      0.17      0.15         6\n",
      "        314       0.59      0.83      0.69        12\n",
      "        315       0.00      0.00      0.00         2\n",
      "        316       0.33      0.31      0.32        16\n",
      "        317       0.00      0.00      0.00         2\n",
      "        318       0.00      0.00      0.00         2\n",
      "        319       1.00      0.25      0.40         4\n",
      "        320       0.00      0.00      0.00         3\n",
      "        321       0.00      0.00      0.00         3\n",
      "        322       0.00      0.00      0.00         8\n",
      "        323       0.83      0.83      0.83         6\n",
      "        324       0.75      0.75      0.75         4\n",
      "        325       0.14      0.12      0.13        17\n",
      "        326       0.62      0.80      0.70        10\n",
      "        327       0.00      0.00      0.00         5\n",
      "        328       0.00      0.00      0.00         0\n",
      "        329       0.75      0.60      0.67         5\n",
      "        330       0.59      0.55      0.57       145\n",
      "        331       0.50      0.14      0.22         7\n",
      "        332       1.00      0.67      0.80         3\n",
      "        333       1.00      0.33      0.50         3\n",
      "        334       0.00      0.00      0.00         3\n",
      "        335       0.00      0.00      0.00         3\n",
      "        336       0.00      0.00      0.00         3\n",
      "        337       0.00      0.00      0.00         0\n",
      "        338       0.67      0.67      0.67         9\n",
      "        339       1.00      0.75      0.86         4\n",
      "        340       1.00      1.00      1.00         1\n",
      "        341       0.00      0.00      0.00         3\n",
      "        342       0.62      0.83      0.71         6\n",
      "        343       0.00      0.00      0.00         2\n",
      "        344       0.33      0.33      0.33         3\n",
      "        345       0.50      0.50      0.50         2\n",
      "        346       0.00      0.00      0.00         1\n",
      "        347       0.00      0.00      0.00         2\n",
      "        348       0.74      0.67      0.70        63\n",
      "        349       1.00      0.62      0.77         8\n",
      "        350       0.00      0.00      0.00        11\n",
      "        351       0.00      0.00      0.00         7\n",
      "        352       0.33      0.33      0.33         3\n",
      "        353       0.00      0.00      0.00         0\n",
      "        354       0.50      0.67      0.57         3\n",
      "        355       0.60      0.38      0.46         8\n",
      "        356       0.00      0.00      0.00         1\n",
      "        357       0.00      0.00      0.00         5\n",
      "        358       0.00      0.00      0.00         1\n",
      "        359       0.73      0.69      0.71        16\n",
      "        360       0.00      0.00      0.00         2\n",
      "        361       0.20      0.25      0.22         4\n",
      "        362       0.00      0.00      0.00         3\n",
      "        363       0.44      0.55      0.49        20\n",
      "        364       0.78      0.78      0.78        36\n",
      "        365       0.33      0.33      0.33        15\n",
      "        366       0.00      0.00      0.00         0\n",
      "        367       0.33      0.33      0.33         3\n",
      "        368       0.33      0.40      0.36         5\n",
      "        369       0.00      0.00      0.00         3\n",
      "        370       0.00      0.00      0.00         5\n",
      "        371       0.00      0.00      0.00         1\n",
      "        372       0.00      0.00      0.00         2\n",
      "        373       0.00      0.00      0.00         4\n",
      "        374       0.25      0.14      0.18         7\n",
      "        375       0.00      0.00      0.00         3\n",
      "        376       0.00      0.00      0.00         1\n",
      "        377       0.50      0.50      0.50         2\n",
      "        378       0.00      0.00      0.00         0\n",
      "        379       0.33      0.50      0.40         2\n",
      "        380       0.75      0.75      0.75         4\n",
      "        381       0.00      0.00      0.00         1\n",
      "        382       1.00      0.20      0.33         5\n",
      "        383       0.12      0.33      0.18         3\n",
      "        384       0.50      0.14      0.22         7\n",
      "        385       0.82      0.93      0.87        15\n",
      "        386       0.00      0.00      0.00         2\n",
      "        387       0.00      0.00      0.00         4\n",
      "        388       0.50      1.00      0.67         2\n",
      "        389       0.00      0.00      0.00         1\n",
      "        390       0.50      1.00      0.67         1\n",
      "        391       0.14      0.25      0.18         4\n",
      "        392       0.00      0.00      0.00         4\n",
      "        393       0.55      0.75      0.63         8\n",
      "        394       0.50      0.50      0.50         2\n",
      "        395       0.32      0.23      0.27        60\n",
      "        396       0.42      0.36      0.38        28\n",
      "        397       0.50      0.44      0.47         9\n",
      "        398       0.12      0.07      0.09        14\n",
      "        399       1.00      0.60      0.75         5\n",
      "        400       0.60      0.60      0.60         5\n",
      "        401       0.50      0.17      0.25        12\n",
      "        402       0.00      0.00      0.00         3\n",
      "        403       0.00      0.00      0.00         1\n",
      "        404       0.50      1.00      0.67         1\n",
      "        405       0.44      1.00      0.62         4\n",
      "        406       0.00      0.00      0.00         1\n",
      "        407       0.00      0.00      0.00         1\n",
      "        408       0.33      0.29      0.31         7\n",
      "        409       0.00      0.00      0.00         1\n",
      "        410       1.00      1.00      1.00         3\n",
      "        411       0.50      1.00      0.67         3\n",
      "        412       0.78      0.88      0.82         8\n",
      "        413       1.00      0.36      0.53        11\n",
      "        414       1.00      0.50      0.67         4\n",
      "        415       0.00      0.00      0.00         2\n",
      "        416       0.00      0.00      0.00         9\n",
      "        417       0.00      0.00      0.00         2\n",
      "        418       0.33      0.17      0.22         6\n",
      "        419       0.33      0.33      0.33         3\n",
      "        420       0.33      0.33      0.33         3\n",
      "        421       0.00      0.00      0.00         4\n",
      "        422       0.00      0.00      0.00         1\n",
      "        423       0.50      0.50      0.50         2\n",
      "        424       0.00      0.00      0.00         0\n",
      "        425       0.50      1.00      0.67         1\n",
      "        426       0.00      0.00      0.00         0\n",
      "        427       0.00      0.00      0.00         3\n",
      "        428       0.00      0.00      0.00         1\n",
      "        429       0.80      0.80      0.80         5\n",
      "        430       0.33      0.11      0.17         9\n",
      "        431       1.00      1.00      1.00         1\n",
      "        432       0.25      0.50      0.33         2\n",
      "        433       0.00      0.00      0.00         1\n",
      "        434       0.22      0.18      0.20        11\n",
      "        435       0.00      0.00      0.00         2\n",
      "        436       0.38      0.50      0.43         6\n",
      "        437       0.00      0.00      0.00         1\n",
      "        438       0.33      1.00      0.50         1\n",
      "        439       0.00      0.00      0.00         2\n",
      "        440       0.33      0.20      0.25         5\n",
      "        441       0.00      0.00      0.00         5\n",
      "        442       0.00      0.00      0.00         2\n",
      "        443       0.33      0.33      0.33         3\n",
      "        444       0.00      0.00      0.00         6\n",
      "        445       0.33      1.00      0.50         2\n",
      "        446       0.33      0.50      0.40         2\n",
      "        447       0.00      0.00      0.00         0\n",
      "        448       0.00      0.00      0.00         0\n",
      "        449       0.67      0.67      0.67         3\n",
      "        450       0.33      0.25      0.29         4\n",
      "        451       0.00      0.00      0.00         2\n",
      "        452       0.43      0.47      0.45        19\n",
      "        453       0.00      0.00      0.00         0\n",
      "        454       0.44      0.67      0.53         6\n",
      "        455       0.50      0.33      0.40         3\n",
      "        456       0.00      0.00      0.00         1\n",
      "        457       0.75      0.50      0.60         6\n",
      "        458       0.00      0.00      0.00         4\n",
      "        459       1.00      1.00      1.00         4\n",
      "        460       1.00      1.00      1.00         1\n",
      "        461       1.00      0.33      0.50         3\n",
      "        462       0.00      0.00      0.00         2\n",
      "        463       0.25      0.25      0.25         8\n",
      "        464       0.20      0.20      0.20         5\n",
      "        465       0.67      0.29      0.40        14\n",
      "        466       0.86      0.75      0.80        16\n",
      "        467       0.00      0.00      0.00         2\n",
      "        468       0.25      0.17      0.20         6\n",
      "        469       0.00      0.00      0.00         5\n",
      "        470       0.36      0.56      0.43         9\n",
      "        471       1.00      0.50      0.67         2\n",
      "        472       0.00      0.00      0.00         1\n",
      "        473       0.00      0.00      0.00         1\n",
      "        474       0.00      0.00      0.00         3\n",
      "        475       0.26      0.19      0.22        37\n",
      "        476       0.35      0.35      0.35        17\n",
      "        477       1.00      0.33      0.50         6\n",
      "        478       0.80      0.50      0.62         8\n",
      "        479       0.20      0.33      0.25         3\n",
      "        480       0.00      0.00      0.00         5\n",
      "        481       0.00      0.00      0.00         4\n",
      "        482       1.00      0.67      0.80         3\n",
      "        483       0.00      0.00      0.00         2\n",
      "        484       0.29      0.40      0.33         5\n",
      "        485       0.12      0.10      0.11        10\n",
      "        486       0.20      1.00      0.33         1\n",
      "        487       0.11      0.09      0.10        11\n",
      "        488       0.50      0.67      0.57         3\n",
      "        489       0.70      0.74      0.72        19\n",
      "        490       0.00      0.00      0.00         3\n",
      "        491       0.00      0.00      0.00         4\n",
      "        492       0.29      0.31      0.30        16\n",
      "        493       0.00      0.00      0.00         2\n",
      "        494       0.48      0.44      0.46        27\n",
      "        495       1.00      0.75      0.86         4\n",
      "        496       0.40      0.67      0.50         3\n",
      "        497       1.00      0.67      0.80         6\n",
      "        498       1.00      0.50      0.67         2\n",
      "        499       0.40      0.50      0.44         4\n",
      "\n",
      "avg / total       0.44      0.38      0.39      3669\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\long\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\long\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning CountVectorizer to Fit DecisionTreeClassifier\n",
    "### Max_features: 50\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "`max_features` parameter is self-explanatory. It will choose the number of words or features set in its' vocabulary and drop everything else.\n",
    "\n",
    "Setting `max_features` as 50 for `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_features_CountVect(n):\n",
    "    tfidf_vectorizer = TfidfVectorizer(min_df = 0.00009, max_features = 200000, smooth_idf = True, norm = \"l2\", \\\n",
    "                                       tokenizer = lambda x: x.split(), sublinear_tf = False, ngram_range = (1, 2))\n",
    "    count_vectorizer_n = CountVectorizer(tokenizer = lambda x: x.split(), binary = 'true', max_features = n)\n",
    "\n",
    "    vectorize_post = tfidf_vectorizer.fit_transform(df['Post'])\n",
    "    vectorize_tags_n = count_vectorizer_n.fit_transform(df['Tags'])\n",
    "\n",
    "    x_train_n, x_test_n, y_train_n, y_test_n = train_test_split(vectorize_post, vectorize_tags_n, random_state = 42, \n",
    "                                                                test_size = 0.2, shuffle = False)\n",
    "    print(x_train_n.shape, x_test_n.shape, y_train_n.shape, y_test_n.shape)\n",
    "    print()\n",
    "    \n",
    "    return x_train_n, x_test_n, y_train_n, y_test_n, count_vectorizer_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200000) (2000, 200000) (8000, 50) (2000, 50)\n",
      "\n",
      "Micro F1 Score: 0.469\n",
      "Micro Precision: 0.506\n",
      "Micro Recall: 0.438\n",
      "Accuracy: 0.376\n",
      "Wall time: 3min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 4min 51s\n",
    "\n",
    "x_train_50, x_test_50, y_train_50, y_test_50, count_vectorizer_50 = max_features_CountVect(50)\n",
    "dtc = DecisionTreeClassifier()                                                                                                 \n",
    "dt_f1_50, dt_precision_50, dt_recall_50, dt_accuracy_50, y_pred_dt50 = train_model(OneVsRestClassifier(dtc, n_jobs = -1), \n",
    "                                                                                   x_train_50, x_test_50, \n",
    "                                                                                   y_train_50, y_test_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max_features: 100\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "Setting `max_features` as 100 for `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200000) (2000, 200000) (8000, 100) (2000, 100)\n",
      "\n",
      "Micro F1 Score: 0.453\n",
      "Micro Precision: 0.483\n",
      "Micro Recall: 0.428\n",
      "Accuracy: 0.302\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 5min 32s\n",
    "\n",
    "x_train_1, x_test_1, y_train_1, y_test_1, count_vectorizer_1 = max_features_CountVect(100)\n",
    "dtc = DecisionTreeClassifier()                                                                                                 \n",
    "dt_f1_1, dt_precision_1, dt_recall_1, dt_accuracy_1, y_pred_dt1 = train_model(OneVsRestClassifier(dtc, n_jobs = -1), \n",
    "                                                                              x_train_1, x_test_1, y_train_1, y_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max_features: 200\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "Setting `max_features` as 200 for `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200000) (2000, 200000) (8000, 200) (2000, 200)\n",
      "\n",
      "Micro F1 Score: 0.446\n",
      "Micro Precision: 0.476\n",
      "Micro Recall: 0.421\n",
      "Accuracy: 0.227\n",
      "Wall time: 8min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 8min 46s\n",
    "\n",
    "x_train_2, x_test_2, y_train_2, y_test_2, count_vectorizer_2 = max_features_CountVect(200)\n",
    "dt_f1_2, dt_precision_2, dt_recall_2, dt_accuracy_2, y_pred_dt2 = train_model(OneVsRestClassifier(dtc, n_jobs = -1), \n",
    "                                                                              x_train_2, x_test_2, y_train_2, y_test_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max_features: 300\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "Setting `max_features` as 300 for `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200000) (2000, 200000) (8000, 300) (2000, 300)\n",
      "\n",
      "Micro F1 Score: 0.424\n",
      "Micro Precision: 0.448\n",
      "Micro Recall: 0.402\n",
      "Accuracy: 0.174\n",
      "Wall time: 10min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 11min 29s\n",
    "\n",
    "x_train_3, x_test_3, y_train_3, y_test_3, count_vectorizer_3 = max_features_CountVect(300)\n",
    "dt_f1_3, dt_precision_3, dt_recall_3, dt_accuracy_3, y_pred_dt3 = train_model(OneVsRestClassifier(dtc, n_jobs = -1), \n",
    "                                                                              x_train_3, x_test_3, y_train_3, y_test_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max_features: 400\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "Setting `max_features` as 400 for `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200000) (2000, 200000) (8000, 400) (2000, 400)\n",
      "\n",
      "Micro F1 Score: 0.412\n",
      "Micro Precision: 0.447\n",
      "Micro Recall: 0.381\n",
      "Accuracy: 0.157\n",
      "Wall time: 12min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 14min 14s\n",
    "\n",
    "x_train_4, x_test_4, y_train_4, y_test_4, count_vectorizer_4 = max_features_CountVect(400)\n",
    "dt_f1_4, dt_precision_4, dt_recall_4, dt_accuracy_4, y_pred_dt4 = train_model(OneVsRestClassifier(dtc, n_jobs = -1), \n",
    "                                                                              x_train_4, x_test_4, y_train_4, y_test_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max_features: 500\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "Setting `max_features` as 500 for `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200000) (2000, 200000) (8000, 500) (2000, 500)\n",
      "\n",
      "Micro F1 Score: 0.405\n",
      "Micro Precision: 0.437\n",
      "Micro Recall: 0.377\n",
      "Accuracy: 0.138\n",
      "Wall time: 15min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 17min 12s\n",
    "\n",
    "x_train_5, x_test_5, y_train_5, y_test_5, count_vectorizer_5 = max_features_CountVect(500)\n",
    "dt_f1_5, dt_precision_5, dt_recall_5, dt_accuracy_5, y_pred_dt5 = train_model(OneVsRestClassifier(dtc, n_jobs = -1), \n",
    "                                                                              x_train_5, x_test_5, y_train_5, y_test_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max_features: 1000\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "Setting `max_features` as 1000 for `CountVectorizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8000, 200000) (2000, 200000) (8000, 1000) (2000, 1000)\n",
      "\n",
      "Micro F1 Score: 0.385\n",
      "Micro Precision: 0.419\n",
      "Micro Recall: 0.356\n",
      "Accuracy: 0.088\n",
      "Wall time: 25min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 15min 52s\n",
    "\n",
    "x_train_10, x_test_10, y_train_10, y_test_10, count_vectorizer_10 = max_features_CountVect(1000)\n",
    "dt_f1_10, dt_precision_10, dt_recall_10, dt_accuracy_10, y_pred_dt10 = train_model(OneVsRestClassifier(dtc, n_jobs = -1), \n",
    "                                                                                   x_train_10, x_test_10, \n",
    "                                                                                   y_train_10, y_test_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation Metrics for DecisionTreeClassifier\n",
    "[Top](#Part-2:-Machine-Learning-Models)\n",
    "\n",
    "It seems that the larger the number of `max_features` in the dataset, the lower is the Micro F1-Score. From the table below, `max_features:50` gives the highest Micro F1 Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Micro F1 Score</th>\n",
       "      <th>Micro Precision</th>\n",
       "      <th>Micro Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Max_features: 50</th>\n",
       "      <td>0.469333</td>\n",
       "      <td>0.506038</td>\n",
       "      <td>0.437593</td>\n",
       "      <td>0.3760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_features: 100</th>\n",
       "      <td>0.453374</td>\n",
       "      <td>0.482566</td>\n",
       "      <td>0.427512</td>\n",
       "      <td>0.3025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_features: 200</th>\n",
       "      <td>0.446480</td>\n",
       "      <td>0.475698</td>\n",
       "      <td>0.420643</td>\n",
       "      <td>0.2270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_features: 300</th>\n",
       "      <td>0.423701</td>\n",
       "      <td>0.448454</td>\n",
       "      <td>0.401538</td>\n",
       "      <td>0.1745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_features: 400</th>\n",
       "      <td>0.411692</td>\n",
       "      <td>0.447342</td>\n",
       "      <td>0.381305</td>\n",
       "      <td>0.1570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_features: 500</th>\n",
       "      <td>0.404623</td>\n",
       "      <td>0.436691</td>\n",
       "      <td>0.376942</td>\n",
       "      <td>0.1380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Max_features: 1000</th>\n",
       "      <td>0.385363</td>\n",
       "      <td>0.419390</td>\n",
       "      <td>0.356443</td>\n",
       "      <td>0.0885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Micro F1 Score  Micro Precision  Micro Recall  Accuracy\n",
       "Max_features: 50          0.469333         0.506038      0.437593    0.3760\n",
       "Max_features: 100         0.453374         0.482566      0.427512    0.3025\n",
       "Max_features: 200         0.446480         0.475698      0.420643    0.2270\n",
       "Max_features: 300         0.423701         0.448454      0.401538    0.1745\n",
       "Max_features: 400         0.411692         0.447342      0.381305    0.1570\n",
       "Max_features: 500         0.404623         0.436691      0.376942    0.1380\n",
       "Max_features: 1000        0.385363         0.419390      0.356443    0.0885"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_results = pd.DataFrame({'Micro F1 Score': dt_f1_50, 'Micro Precision': dt_precision_50, 'Micro Recall': dt_recall_50, \n",
    "                           'Accuracy': dt_accuracy_50}, index = ['Max_features: 50'])\n",
    "dt_results.loc['Max_features: 100'] = dt_f1_1, dt_precision_1, dt_recall_1, dt_accuracy_1\n",
    "dt_results.loc['Max_features: 200'] = dt_f1_2, dt_precision_2, dt_recall_2, dt_accuracy_2\n",
    "dt_results.loc['Max_features: 300'] = dt_f1_3, dt_precision_3, dt_recall_3, dt_accuracy_3\n",
    "dt_results.loc['Max_features: 400'] = dt_f1_4, dt_precision_4, dt_recall_4, dt_accuracy_4\n",
    "dt_results.loc['Max_features: 500'] = dt_f1_5, dt_precision_5, dt_recall_5, dt_accuracy_5\n",
    "dt_results.loc['Max_features: 1000'] = dt_f1_10, dt_precision_10, dt_recall_10, dt_accuracy_10\n",
    "dt_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Making Predictions\n",
    "### Tags Prediction\n",
    "[Top](#Part-3:-Making-Predictions)\n",
    "\n",
    "Listing the tags predicted by all `DecisionTreeClassifier` fine-tuned models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_tags_50 = count_vectorizer_50.inverse_transform(y_pred_dt50) \n",
    "pred_tags_1 = count_vectorizer_1.inverse_transform(y_pred_dt1) \n",
    "pred_tags_2 = count_vectorizer_2.inverse_transform(y_pred_dt2) \n",
    "pred_tags_3 = count_vectorizer_3.inverse_transform(y_pred_dt3) \n",
    "pred_tags_4 = count_vectorizer_4.inverse_transform(y_pred_dt4) \n",
    "pred_tags_5 = count_vectorizer_5.inverse_transform(y_pred_dt5) \n",
    "pred_tags_10 = count_vectorizer_10.inverse_transform(y_pred_dt10)\n",
    "actual_tags = count_vectorizer.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual Tags (y_test)</th>\n",
       "      <th>Max_features:50</th>\n",
       "      <th>Max_features:100</th>\n",
       "      <th>Max_features:200</th>\n",
       "      <th>Max_features:300</th>\n",
       "      <th>Max_features:400</th>\n",
       "      <th>Max_features:500</th>\n",
       "      <th>Max_features:1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[sql, mysql, sql-server]</td>\n",
       "      <td>[database, sql]</td>\n",
       "      <td>[sql]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[sql]</td>\n",
       "      <td>[sql]</td>\n",
       "      <td>[sql]</td>\n",
       "      <td>[java, query]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ajax, codeigniter]</td>\n",
       "      <td>[ajax, asp.net, jquery, php]</td>\n",
       "      <td>[ajax, asp.net, codeigniter, jquery, php]</td>\n",
       "      <td>[asp.net, codeigniter, jquery, php]</td>\n",
       "      <td>[ajax, codeigniter, jquery, php]</td>\n",
       "      <td>[ajax, codeigniter, jquery]</td>\n",
       "      <td>[asp.net, codeigniter, jquery, php, twitter-bo...</td>\n",
       "      <td>[asp.net, codeigniter, jquery, php, twitter-bo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[sql-server, sql-server-2008]</td>\n",
       "      <td>[android, sql]</td>\n",
       "      <td>[.net, android, ruby-on-rails, sql, visual-stu...</td>\n",
       "      <td>[android, sql]</td>\n",
       "      <td>[android, sql, stored-procedures]</td>\n",
       "      <td>[android, sql, stored-procedures]</td>\n",
       "      <td>[android, sql, stored-procedures]</td>\n",
       "      <td>[android, count, sql, stored-procedures]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[php]</td>\n",
       "      <td>[php, shell]</td>\n",
       "      <td>[php]</td>\n",
       "      <td>[bash, php]</td>\n",
       "      <td>[php, silverlight-4.0]</td>\n",
       "      <td>[objective-c, php, windows-7, zend-framework2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[php, javascript, jquery]</td>\n",
       "      <td>[ajax]</td>\n",
       "      <td>[ajax]</td>\n",
       "      <td>[ajax, performance]</td>\n",
       "      <td>[ajax]</td>\n",
       "      <td>[ajax]</td>\n",
       "      <td>[ajax, wcf]</td>\n",
       "      <td>[ajax, frameworks]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[linq, query, nhibernate]</td>\n",
       "      <td>[.net, c#, linq]</td>\n",
       "      <td>[.net, asp.net, linq]</td>\n",
       "      <td>[.net, c#, linq, nhibernate]</td>\n",
       "      <td>[c#, linq, nhibernate]</td>\n",
       "      <td>[.net, c#, linq, nhibernate]</td>\n",
       "      <td>[.net, c#, linq, nhibernate]</td>\n",
       "      <td>[asp.net, azure, c#, linq, nhibernate]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[crystal-reports, delphi]</td>\n",
       "      <td>[vb.net]</td>\n",
       "      <td>[vb.net]</td>\n",
       "      <td>[delphi, vb.net]</td>\n",
       "      <td>[delphi, jquery, vb.net]</td>\n",
       "      <td>[crystal-reports, delphi, jquery-selectors, vb...</td>\n",
       "      <td>[crystal-reports, delphi, jquery, vb.net]</td>\n",
       "      <td>[crystal-reports, delphi, jquery, vb.net]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[javascript, html5]</td>\n",
       "      <td>[html5, javascript]</td>\n",
       "      <td>[html5, javascript]</td>\n",
       "      <td>[canvas, html5, javascript]</td>\n",
       "      <td>[canvas, html5, javascript]</td>\n",
       "      <td>[canvas, html5, javascript]</td>\n",
       "      <td>[canvas, html5, javascript, tikz-pgf]</td>\n",
       "      <td>[canvas, html5, javascript]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[java]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[java, memory-management, memory-leaks]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[java, ubuntu]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[java]</td>\n",
       "      <td>[java]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Actual Tags (y_test)               Max_features:50  \\\n",
       "0                 [sql, mysql, sql-server]               [database, sql]   \n",
       "1                      [ajax, codeigniter]  [ajax, asp.net, jquery, php]   \n",
       "2            [sql-server, sql-server-2008]                [android, sql]   \n",
       "3                                       []                            []   \n",
       "4                [php, javascript, jquery]                        [ajax]   \n",
       "5                [linq, query, nhibernate]              [.net, c#, linq]   \n",
       "6                [crystal-reports, delphi]                      [vb.net]   \n",
       "7                      [javascript, html5]           [html5, javascript]   \n",
       "8                                   [java]                        [java]   \n",
       "9  [java, memory-management, memory-leaks]                        [java]   \n",
       "\n",
       "                                    Max_features:100  \\\n",
       "0                                              [sql]   \n",
       "1          [ajax, asp.net, codeigniter, jquery, php]   \n",
       "2  [.net, android, ruby-on-rails, sql, visual-stu...   \n",
       "3                                              [php]   \n",
       "4                                             [ajax]   \n",
       "5                              [.net, asp.net, linq]   \n",
       "6                                           [vb.net]   \n",
       "7                                [html5, javascript]   \n",
       "8                                             [java]   \n",
       "9                                             [java]   \n",
       "\n",
       "                      Max_features:200                   Max_features:300  \\\n",
       "0                               [java]                              [sql]   \n",
       "1  [asp.net, codeigniter, jquery, php]   [ajax, codeigniter, jquery, php]   \n",
       "2                       [android, sql]  [android, sql, stored-procedures]   \n",
       "3                         [php, shell]                              [php]   \n",
       "4                  [ajax, performance]                             [ajax]   \n",
       "5         [.net, c#, linq, nhibernate]             [c#, linq, nhibernate]   \n",
       "6                     [delphi, vb.net]           [delphi, jquery, vb.net]   \n",
       "7          [canvas, html5, javascript]        [canvas, html5, javascript]   \n",
       "8                               [java]                             [java]   \n",
       "9                               [java]                     [java, ubuntu]   \n",
       "\n",
       "                                    Max_features:400  \\\n",
       "0                                              [sql]   \n",
       "1                        [ajax, codeigniter, jquery]   \n",
       "2                  [android, sql, stored-procedures]   \n",
       "3                                        [bash, php]   \n",
       "4                                             [ajax]   \n",
       "5                       [.net, c#, linq, nhibernate]   \n",
       "6  [crystal-reports, delphi, jquery-selectors, vb...   \n",
       "7                        [canvas, html5, javascript]   \n",
       "8                                             [java]   \n",
       "9                                             [java]   \n",
       "\n",
       "                                    Max_features:500  \\\n",
       "0                                              [sql]   \n",
       "1  [asp.net, codeigniter, jquery, php, twitter-bo...   \n",
       "2                  [android, sql, stored-procedures]   \n",
       "3                             [php, silverlight-4.0]   \n",
       "4                                        [ajax, wcf]   \n",
       "5                       [.net, c#, linq, nhibernate]   \n",
       "6          [crystal-reports, delphi, jquery, vb.net]   \n",
       "7              [canvas, html5, javascript, tikz-pgf]   \n",
       "8                                             [java]   \n",
       "9                                             [java]   \n",
       "\n",
       "                                   Max_features:1000  \n",
       "0                                      [java, query]  \n",
       "1  [asp.net, codeigniter, jquery, php, twitter-bo...  \n",
       "2           [android, count, sql, stored-procedures]  \n",
       "3     [objective-c, php, windows-7, zend-framework2]  \n",
       "4                                 [ajax, frameworks]  \n",
       "5             [asp.net, azure, c#, linq, nhibernate]  \n",
       "6          [crystal-reports, delphi, jquery, vb.net]  \n",
       "7                        [canvas, html5, javascript]  \n",
       "8                                                 []  \n",
       "9                                             [java]  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_table = pd.DataFrame({'Actual Tags (y_test)': actual_tags, 'Max_features:50': pred_tags_50})\n",
    "tags_table['Max_features:100'] = pred_tags_1\n",
    "tags_table['Max_features:200'] = pred_tags_2\n",
    "tags_table['Max_features:300'] = pred_tags_3\n",
    "tags_table['Max_features:400'] = pred_tags_4\n",
    "tags_table['Max_features:500'] = pred_tags_5\n",
    "tags_table['Max_features:1000'] = pred_tags_10\n",
    "tags_table.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing predicted tags from `max_features:50` with `Title`, `Body` columns and actual tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Wall time: 18 s\n",
    "\n",
    "actual_df = pd.read_csv(filename, nrows = no_of_rows)\n",
    "actual_df['Body'] = actual_df['Body'].apply(lambda x: bs4.BeautifulSoup(x, 'lxml').get_text()) \n",
    "actual_df['Body'] = actual_df['Body'].apply(lambda x: clean_text(x)) \n",
    "actual_df['Body'] = actual_df['Body'].apply(lambda x: clean_punct(x)) \n",
    "\n",
    "actual_body = actual_df.Body[len(df) - y_test.shape[0]:]\n",
    "actual_title = actual_df.Title[len(df) - y_test.shape[0]:]\n",
    "actual_body = actual_body.reset_index(drop = True)\n",
    "actual_title = actual_title.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTitle: how do you delete a row, if this has foreign keys? sql\u001b[0m\n",
      "\u001b[1mBody:\u001b[0m for example if you have this rows create table table1 column1 int primary key column2 varchar 50 column3 varchar 50 column4 varchar 50 create table tabla2 col1 int primary key col2 int col3 varchar 50 foreign key col2 references table1 column1 and for example i have a row insert into table1 column1 column2 column3 column4 values 1 a b c insert into table2 col1 col2 col3 values 11 xxx and i want to delete all these rows just them delete from table1 where colum11 does not work i know i can first delete the another and after it but i have a database with a lot of tables and they have a foreign key since another table and i want to delete the row for all rows are relationed with this delete too\n",
      "\u001b[91m\u001b[1m\n",
      "Predicted tags:\u001b[0m ['database' 'sql']\n",
      "\u001b[94m\u001b[1mActual tags:\u001b[0m ['sql' 'mysql' 'sql-server']\n",
      "\n",
      "\u001b[1mTitle: Redirect in codeigniter after login\u001b[0m\n",
      "\u001b[1mBody:\u001b[0m trying to do a redirect after a successful login the login info is sent using ajax to the controller my controller code as below public function logincontrollerfunction this-load-model loginmodel if this-input-isajaxrequest username this-input-post username userpassword this-input-post password this-load-helper url result this-loginmodel-verifyuser username userpassword echo userloggedin if strcmp result userloggedin 0 redirect welcome but it is not working at all anyone knows whats wrong hi my html as requested i am using twitter bootstrap as well li class divider-vertical li lia href # id loginbtn loginali lia href php echo baseurl are gister registerali for the buttons so when i click the login button a modal window will appear and ask for login info so when i click on the login button my js code will send an ajax request my js code as below attempt register user jquery ajax #login click function var username #loginhere find #username val var userpassword #loginhere find #loginpwd val if username #124 #124 userpassword return var logindata username username password userpassword ajax type post datatype json async false url loginregisterlogincontrollerfunction data logindata success function data if datalogin alert dataredirect windowlocationreplace dataredirect else if datalogin alert would ata login not true error function data alert ajax error\n",
      "\u001b[91m\u001b[1m\n",
      "Predicted tags:\u001b[0m ['ajax' 'asp.net' 'jquery' 'php']\n",
      "\u001b[94m\u001b[1mActual tags:\u001b[0m ['ajax' 'codeigniter']\n",
      "\n",
      "\u001b[1mTitle: SQL Server Merge statement\u001b[0m\n",
      "\u001b[1mBody:\u001b[0m i am doing merge statement in my stored procedure i need to count the rows during updates and inserts if i use a common variable to get the updated rows for both update and insert how i can differ this is the count which i got from update and this is the count which i got from insert please give me a better way\n",
      "\u001b[91m\u001b[1m\n",
      "Predicted tags:\u001b[0m ['android' 'sql']\n",
      "\u001b[94m\u001b[1mActual tags:\u001b[0m ['sql-server' 'sql-server-2008']\n",
      "\n",
      "\u001b[1mTitle: Problems with getting BjyAuthorize activated in zend-developer-toolbar ZF2\u001b[0m\n",
      "\u001b[1mBody:\u001b[0m can someone give me some instructions on how to get the user roles into my zf2-toolbar i have problems getting the user-roles from my role-entity visible in my zend-developer-toolbar normaly i solve my own problems but in this case i am out of ideas i am using zfcuser bjyauthorize and doctrine2 i cannot find any instructions on how to make the user-roles show up on the toolbar i used composer to install all dependencies my composer file looks like this require php 533 zendframeworkzendframework 2 doctrinecommon 23-dev 25-dev zf-commonszfc-user 0 bjyoungbloodbjy-authorize 12 doctrinedoctrine-orm-module 0 zendframeworkzftool dev-master zendframeworkzend-developer-tools dev-master zf-commonszfc-user-doctrine-orm dev-master bjyoungbloodbjy-profiler dev-master in the toolbar i also still get the message error you have to install or enable bjyoungblood zenddb profiler to use this feature while in my configautoloadmodulezenddevelopertoolslocalphp i did set the profiler to enabled and it is also installed at least i checked that with my composerphar if profiler array enabled true would be great if someone can help me out thx\n",
      "\u001b[91m\u001b[1m\n",
      "Predicted tags:\u001b[0m []\n",
      "\u001b[94m\u001b[1mActual tags:\u001b[0m []\n",
      "\n",
      "\u001b[1mTitle: Calling Ajax and returning response\u001b[0m\n",
      "\u001b[1mBody:\u001b[0m i have search for so many questions but didnt get the right answer i have made the following function from what my research i understand that ajax call is async so on its done passing a value to global variable and returning that but i get a blank or undefined valuei can do it with #someid html in response or some other methods but i dont want to implement them . any idea what i am doing wrong here function simpleajax form postdata url var returndata var senddata if form senddata postdata else if postdata senddata form serialize ajax type post url url cache false data senddata success function data if data null #124 #124 typeof data undefined returndata data done function data returndata data return returndata ​\n",
      "\u001b[91m\u001b[1m\n",
      "Predicted tags:\u001b[0m ['ajax']\n",
      "\u001b[94m\u001b[1mActual tags:\u001b[0m ['php' 'javascript' 'jquery']\n",
      "\n",
      "\u001b[1mTitle: How do you return certain properties from a linq query, rather than complete objects?\u001b[0m\n",
      "\u001b[1mBody:\u001b[0m i have just downloaded the linq provider for nhibernate and am just a little excited but i do not know linq syntax that well i can return whole objects from a query like this var query from foo in sessionlinqkctcbusinesslayerdomaincase where foocasenumber 0 select foo and i can select a single property like this var query from foo in sessionlinqkctcbusinesslayerdomaincase where foocasenumber 0 select fooid but how would i select two properties eg fooid and foobar or is that not possible thanks david\n",
      "\u001b[91m\u001b[1m\n",
      "Predicted tags:\u001b[0m ['.net' 'c#' 'linq']\n",
      "\u001b[94m\u001b[1mActual tags:\u001b[0m ['linq' 'query' 'nhibernate']\n",
      "\n",
      "\u001b[1mTitle: Delphi - Show modal report with Crystal Reports\u001b[0m\n",
      "\u001b[1mBody:\u001b[0m i am using crystal reports 7 and delphi 7 and wondering how to open a modal preview of the report crpe1execute opens a non modal form but i can not find a way to open a modal one thanks for your help\n",
      "\u001b[91m\u001b[1m\n",
      "Predicted tags:\u001b[0m ['vb.net']\n",
      "\u001b[94m\u001b[1mActual tags:\u001b[0m ['crystal-reports' 'delphi']\n",
      "\n",
      "\u001b[1mTitle: Excanvas Javascript wont work in IE8\u001b[0m\n",
      "\u001b[1mBody:\u001b[0m i am using excanvas to work with html5 canvas in ie8 i created a litte jaavascript html5 game and it work great in firefox but when i use excanvas and try it in ie8 the canvas stays black and doesnt show anything the stranged thing is that another game i created worked fine with ie8 excanvas the only difference between these games is that i know use prototype can any one please tell me if this makes a difference or help solve this problem thank you in advance .\n",
      "\u001b[91m\u001b[1m\n",
      "Predicted tags:\u001b[0m ['html5' 'javascript']\n",
      "\u001b[94m\u001b[1mActual tags:\u001b[0m ['javascript' 'html5']\n",
      "\n",
      "\u001b[1mTitle: Java, multiple iterators on a set, removing proper subsets and ConcurrentModificationException\u001b[0m\n",
      "\u001b[1mBody:\u001b[0m i have a set a 12 123 234 34 1 i want to turn it into a 123 234 remove proper subsets from this set i am using a hashset to implement the set 2 iterator to run through the set and check all pairs for proper subset condition using containsall c and the remove method to remove proper subsets the code looks something like this hashsetinteger hs setinteger chsvalues iteratorinteger it citerator while ithasnext pitnext iteratorinteger it2 citerator while it2hasnext qit2next if q is a subset of p it2remove else if p is a subset of q itremove break i get a concurrentmodificationexception the 1st time i come out of the inner while loop and do a pitnext the exception is for when modifying the collection while iterating over it but that what remove is for i have used remove when using just 1 iterator and encountered no problems there if the exception is because i am removing an element from c or hs while iterating over it then the exception should be thrown when it encounter the very next it 2 next command but i do not see it then i see it when it encounters the itnext command i used the debugger and the collections and iterators are in perfect order after the element has been removed they contain and point to the proper updated set and element itnext contains the next element to be analyzed it not a deleted element any ideas over how i can do what i am trying to do without making a copy of the hashset itself and using it as an intermediate before i commit updates thank you\n",
      "\u001b[91m\u001b[1m\n",
      "Predicted tags:\u001b[0m ['java']\n",
      "\u001b[94m\u001b[1mActual tags:\u001b[0m ['java']\n",
      "\n",
      "\u001b[1mTitle: Java Webapp: strange memory statistics\u001b[0m\n",
      "\u001b[1mBody:\u001b[0m i am running a java web application j2ee+tomcat6+struts2+hibernate on a linux centos machine the problem is the top command says java is using 14 of memory out of 8g but in the summary information section says the overall free memory is 300m just mem not swap pid user pr ni virt res shr s cpu mem time+ swap time code data nflt command 666 root 20 0 1352m 12g 10m s 76 147 663 0037 158m 663 00 36 13g 65 java 3170 mysql 18 0 145m 33m 5044 s 07 04 753 5196 111m 753 51 6496 132m 100 mysqld 17340 root 15 0 2332 1080 800 r 03 00 0 0005 1252 0 00 56 468 0 top 1 root 15 0 2068 628 536 s 00 00 0 0258 1440 0 02 32 280 20 init 2 root rt -5 0 0 0 s 00 00 0 0018 0 0 00 0 0 0 migration0 3 root 34 19 0 0 0 s 00 00 0 0000 0 0 00 0 0 0 ksoftirqd0 4 root rt -5 0 0 0 s 00 00 0 0000 0 0 00 0 0 0 watchdog0 5 root rt -5 0 0 0 s 00 00 0 0001 0 0 00 0 0 0 migration1 6 root 34 19 0 0 0 s 00 00 0 0000 0 0 00 0 0 0 ksoftirqd1 7 root rt -5 0 0 0 s 00 00 0 0000 0 0 00 0 0 0 watchdog1 8 root rt -5 0 0 0 s 00 00 0 0001 0 0 00 0 0 0 migration2 . . . and so on mem 8300688k total 7998720k used 301968k free 52452k buffers swap 16779884k total 60k used 16779824k free 6511228k cached what is the problem what could be using memory covertly non-heap or what thanks buddies .\n",
      "\u001b[91m\u001b[1m\n",
      "Predicted tags:\u001b[0m ['java']\n",
      "\u001b[94m\u001b[1mActual tags:\u001b[0m ['java' 'memory-management' 'memory-leaks']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class color:\n",
    "    BOLD = '\\033[1m'\n",
    "    END = '\\033[0m'\n",
    "    BLUE = '\\033[94m'\n",
    "    RED = '\\033[91m'\n",
    "    \n",
    "for i in range(0, 10):\n",
    "    print(color.BOLD + \"Title: \" + actual_title[i] + color.END)\n",
    "    print(color.BOLD + \"Body:\" + color.END, actual_body[i])\n",
    "    print(color.RED + color.BOLD + \"\\nPredicted tags:\" + color.END, pred_tags_50[i])\n",
    "    print(color.BLUE + color.BOLD + \"Actual tags:\" + color.END, actual_tags[i])\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
